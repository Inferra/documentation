---
title: "FAQ"
description: "Frequently asked questions about the Inferra.net API"
---

<Warning>
  **Note:** Inferra is currently in beta. Some features may change.
</Warning>

### Does Inferra support streaming?

Yes, Inferra supports streaming for all language models. Simply set the `stream=true` parameter in your request.

### &#xA;Does Inferra support batching?

Yes, Inferra supports batching for all models. Please [contact us](mailto:support@inferra.net) for details.

### &#xA;Does Inferra support custom models?

No currently, we are working on on supported LoRAs for Llama 3.1 models. If you have a specific use case or would like early access, please [contact us](mailto:support@inferra.net).

### â€‹&#xA;Does Inferra use my data?

No, Inferra does not use your data for training, or any other purpose. We delete all data after 30 days.
